{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "648 fits failed out of a total of 1944.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "229 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "419 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  0.00634359  0.04095183  0.03764821\n",
      "  0.06852884  0.08153722  0.08887064  0.05248025  0.05778713  0.06379905\n",
      "  0.10437848  0.10696817  0.12137027  0.09474469  0.10243465  0.11533968\n",
      "  0.05497864  0.058873    0.07428919  0.08845117  0.0943116   0.1070908\n",
      "  0.08845117  0.0943116   0.1070908   0.07343291  0.08564457  0.09867038\n",
      "  0.04418881  0.04916008  0.05412269  0.08426279  0.10193689  0.10747442\n",
      "  0.07241149  0.0858122   0.09291983  0.11269597  0.12262069  0.13586321\n",
      "  0.13035262  0.12764326  0.13357709  0.08216314  0.09307309  0.09817204\n",
      "  0.11066034  0.11104077  0.11666714  0.11066034  0.11104077  0.11666714\n",
      "  0.09138533  0.09930667  0.10810256         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.03011738  0.05595894  0.04874939  0.08888242  0.08403055  0.09419393\n",
      "  0.05942908  0.0577002   0.06541394  0.11256374  0.11349154  0.11484261\n",
      "  0.11025793  0.11548353  0.1191246   0.05696461  0.05977006  0.07289318\n",
      "  0.08796036  0.09273866  0.10834416  0.08796036  0.09273866  0.10834416\n",
      "  0.0767918   0.08636814  0.09919225  0.02943262  0.03652437  0.05703091\n",
      "  0.09406286  0.10543521  0.11737631  0.08829629  0.09377416  0.09164765\n",
      "  0.11181335  0.12476349  0.13598453  0.11620569  0.12574155  0.12889263\n",
      "  0.09419288  0.09734463  0.0974483   0.10498515  0.10857789  0.11724066\n",
      "  0.10498515  0.10857789  0.11724066  0.09826554  0.10402652  0.11131844\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan  0.02475359  0.05165508  0.0470472\n",
      "  0.08956107  0.08449511  0.09564023  0.05877203  0.05729763  0.06517391\n",
      "  0.11230977  0.11610245  0.11581956  0.11021627  0.11509731  0.11930104\n",
      "  0.05662917  0.05889481  0.07254327  0.08796036  0.09273866  0.10834416\n",
      "  0.08796036  0.09273866  0.10834416  0.0767918   0.08636814  0.09919225\n",
      "  0.04143836  0.04313976  0.05813967  0.09335975  0.10421708  0.11665243\n",
      "  0.08883109  0.09402869  0.09185731  0.11181335  0.12442052  0.13585042\n",
      "  0.11620569  0.12553433  0.1288129   0.09419288  0.09734463  0.09752207\n",
      "  0.10498515  0.10857789  0.11724066  0.10498515  0.10857789  0.11724066\n",
      "  0.09826554  0.10402652  0.11131844         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.02475359  0.05708678  0.04920235  0.08956107  0.08449511  0.09564023\n",
      "  0.05877203  0.05729763  0.06517391  0.11230977  0.11610245  0.11581956\n",
      "  0.11021627  0.11509731  0.11930104  0.05662917  0.05889481  0.07254327\n",
      "  0.08796036  0.09273866  0.10834416  0.08796036  0.09273866  0.10834416\n",
      "  0.0767918   0.08636814  0.09919225  0.04143836  0.04313976  0.05813967\n",
      "  0.09335975  0.10421708  0.11665243  0.08883109  0.09402869  0.09185731\n",
      "  0.11181335  0.12442052  0.13585042  0.11620569  0.12553433  0.1288129\n",
      "  0.09419288  0.09734463  0.09752207  0.10498515  0.10857789  0.11724066\n",
      "  0.10498515  0.10857789  0.11724066  0.09826554  0.10402652  0.11131844\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.19266553 -0.16731768 -0.15614513\n",
      " -0.16020116 -0.13612853 -0.14429451  0.08848104  0.09498588  0.08626982\n",
      "  0.07144905  0.06660837  0.06823407  0.05116663  0.06210046  0.0709478\n",
      "  0.08992609  0.09814897  0.09332028  0.12754464  0.13461422  0.13631497\n",
      "  0.12754464  0.13461422  0.13631497  0.11113148  0.11627269  0.1186445\n",
      " -0.08408365 -0.11184214 -0.09557932 -0.05692083 -0.07866916 -0.07910597\n",
      "  0.13380707  0.13368882  0.13374577  0.10201046  0.09687084  0.10698613\n",
      "  0.10637365  0.10460785  0.10760597  0.13030935  0.13232616  0.14058564\n",
      "  0.14522003  0.14154774  0.14815264  0.14522003  0.14154774  0.14815264\n",
      "  0.13677116  0.13778478  0.14673882         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.17014441 -0.17706137 -0.15412826 -0.15856063 -0.15405294 -0.1490905\n",
      "  0.07984318  0.09354743  0.09639948  0.07089607  0.06191943  0.0700123\n",
      "  0.05595128  0.06433059  0.07722933  0.0935191   0.09731065  0.09247902\n",
      "  0.13401789  0.13627257  0.13771808  0.13401789  0.13627257  0.13771808\n",
      "  0.1173122   0.12585168  0.12493393 -0.07988111 -0.0969437  -0.08551712\n",
      " -0.11729208 -0.10785283 -0.0755898   0.14279745  0.13263679  0.13860513\n",
      "  0.07862753  0.088973    0.1187609   0.08683208  0.09277299  0.11442742\n",
      "  0.13045971  0.12706073  0.14005637  0.14782552  0.14752513  0.15057286\n",
      "  0.14782552  0.14752513  0.15057286  0.13954297  0.13593869  0.14728951\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.17545092 -0.17828748 -0.15710116\n",
      " -0.15425336 -0.1492401  -0.14622526  0.0790011   0.09264946  0.09543999\n",
      "  0.07157775  0.06132524  0.07000652  0.05283527  0.06394265  0.07685681\n",
      "  0.09351885  0.0970482   0.09226062  0.13401789  0.13627257  0.13771808\n",
      "  0.13401789  0.13627257  0.13771808  0.1173122   0.12585168  0.12493393\n",
      " -0.06886569 -0.09978647 -0.09017574 -0.11095755 -0.1055862  -0.07505659\n",
      "  0.14218406  0.13175271  0.13808934  0.08017792  0.08914157  0.11882552\n",
      "  0.09022219  0.09457332  0.11510991  0.13045971  0.12706073  0.14007432\n",
      "  0.14782552  0.14752513  0.15057286  0.14782552  0.14752513  0.15057286\n",
      "  0.13954297  0.13593869  0.14729007         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.1748101  -0.17799921 -0.15698763 -0.15425336 -0.1492401  -0.14622526\n",
      "  0.0790011   0.09264946  0.09543999  0.07157775  0.06132524  0.07000652\n",
      "  0.05283527  0.06394265  0.07685681  0.09351885  0.0970482   0.09226062\n",
      "  0.13401789  0.13627257  0.13771808  0.13401789  0.13627257  0.13771808\n",
      "  0.1173122   0.12585168  0.12493393 -0.06886569 -0.09978647 -0.09017574\n",
      " -0.11095755 -0.1055862  -0.07505659  0.14218406  0.13175271  0.13808934\n",
      "  0.08017792  0.08914157  0.11882552  0.09022219  0.09457332  0.11510991\n",
      "  0.13045971  0.12706073  0.14007432  0.14782552  0.14752513  0.15057286\n",
      "  0.14782552  0.14752513  0.15057286  0.13954297  0.13593869  0.14729007]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Mean Squared Error: 134.1881908065569\n",
      "Best Random Forest R-squared: 0.5314012086581434\n",
      "                              Feature  Importance\n",
      "254  Snow_Volume_Opuha_Catchment_(mm)    0.025231\n",
      "268            Water_Temp_Buoy_(degC)    0.014855\n",
      "269        Water_Temp_Platform_(degC)    0.013508\n",
      "261                           Tdry(C)    0.012450\n",
      "11                         point12_B2    0.011399\n",
      "230                    point11_cs_cdf    0.010998\n",
      "241                    point22_cs_cdf    0.010601\n",
      "240                    point21_cs_cdf    0.010544\n",
      "233                    point14_cs_cdf    0.010447\n",
      "229                    point10_cs_cdf    0.010314\n",
      "231                    point12_cs_cdf    0.009546\n",
      "264                           Tmax(C)    0.009423\n",
      "263                             RH(%)    0.008975\n",
      "220                     point1_cs_cdf    0.008760\n",
      "172                       point19_B11    0.008611\n",
      "160                        point7_B11    0.008155\n",
      "222                     point3_cs_cdf    0.007358\n",
      "43                         point22_B3    0.007314\n",
      "163                       point10_B11    0.007311\n",
      "42                         point21_B3    0.007282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Final_Merged_Data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert 'timestamp_sentinel2' to datetime\n",
    "data['timestamp_sentinel2'] = pd.to_datetime(data['timestamp_sentinel2'])\n",
    "\n",
    "# Define the target variable (y)\n",
    "target = 'Turbidity_Buoy_(NTU)'\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    *[f'point{point}_B{band}' for band in [2, 3, 4, 8, 8, 8, 8, 11, 12] for point in range(1, 23)],\n",
    "    *[f'point{point}_cs' for point in range(1, 23)],\n",
    "    *[f'point{point}_cs_cdf' for point in range(1, 23)],\n",
    "    'B2_AVG', 'B3_AVG', 'B4_AVG', 'B8_AVG', 'B8A_AVG', 'B11_AVG', 'B12_AVG',\n",
    "    'cs_AVG', 'cs_cdf_AVG',\n",
    "    'Ground_Measurements_time_diff_(seconds)', 'Lake_Height_(m)', \n",
    "    'PercentFull_Active_Lake_Storage_(%)', 'Snow_Volume_Opuha_Catchment_(mm)',\n",
    "    'WDir(Deg)', 'WSpd(m/s)', 'GustDir(Deg)', 'GustSpd(m/s)', 'WindRun(Km)', \n",
    "    'Rain(mm)', 'Tdry(C)', 'TWet(C)', 'RH(%)', 'Tmax(C)', 'Tmin(C)', \n",
    "    'Pmsl(hPa)', 'Pstn(hPa)', 'Water_Temp_Buoy_(degC)', 'Water_Temp_Platform_(degC)'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Normalise the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Best Random Forest Mean Squared Error: {mse_rf}\")\n",
    "print(f\"Best Random Forest R-squared: {r2_rf}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = best_rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(20))  # Display top 20 important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1080 candidates, totalling 3240 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Final_Merged_Data.csv')\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert 'timestamp_sentinel2' to datetime\n",
    "data['timestamp_sentinel2'] = pd.to_datetime(data['timestamp_sentinel2'])\n",
    "\n",
    "# Define the target variable (y)\n",
    "target = 'Turbidity_Buoy_(NTU)'\n",
    "\n",
    "# Select features\n",
    "features = [\n",
    "    'B2_AVG', 'B3_AVG', 'B4_AVG', 'B8_AVG', 'B8A_AVG', 'B11_AVG', 'B12_AVG',\n",
    "    'cs_AVG', 'cs_cdf_AVG',\n",
    "    'Ground_Measurements_time_diff_(seconds)', 'Lake_Height_(m)', \n",
    "    'PercentFull_Active_Lake_Storage_(%)', 'Snow_Volume_Opuha_Catchment_(mm)',\n",
    "    'WDir(Deg)', 'WSpd(m/s)', 'GustDir(Deg)', 'GustSpd(m/s)', 'WindRun(Km)', \n",
    "    'Rain(mm)', 'Tdry(C)', 'TWet(C)', 'RH(%)', 'Tmax(C)', 'Tmin(C)', \n",
    "    'Pmsl(hPa)', 'Pstn(hPa)', 'Water_Temp_Buoy_(degC)', 'Water_Temp_Platform_(degC)'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', 0.2, 0.5, 0.7],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Best Random Forest Mean Squared Error: {mse_rf}\")\n",
    "print(f\"Best Random Forest R-squared: {r2_rf}\")\n",
    "\n",
    "# Feature importance\n",
    "importances = best_rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(20))  # Display top 20 important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
