{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be61bd261b2644d1a2e204555fb32a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Plot Type', options=('Scatter Plot', 'Time Series Plot'), valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# from ipywidgets import interact\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = 'Updated_Merged_Data.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# # List of remote sensing variables\n",
    "# remote_sensing_vars = [col for col in data.columns if '_B' in col]\n",
    "\n",
    "# # List of average variables\n",
    "# avg_vars = ['B2_AVG', 'B3_AVG', 'B4_AVG', 'B8_AVG', 'B8A_AVG', 'B11_AVG', 'B12_AVG']\n",
    "\n",
    "# def plot_data(plot_type, x_var, y_var, log_x, log_y, window, filter_cloud, cloud_band, cloud_threshold, custom_var_expr, drop_zero):\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "    \n",
    "#     # Evaluate the custom variable expression if provided\n",
    "#     if custom_var_expr:\n",
    "#         try:\n",
    "#             data['custom_var'] = eval(custom_var_expr, {\"data\": data, \"np\": np})\n",
    "#             x_var = 'custom_var'\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error in custom variable expression: {e}\")\n",
    "#             return\n",
    "    \n",
    "#     # Determine if the selected variable is a remote sensing variable or average variable\n",
    "#     is_remote_sensing = any(var in remote_sensing_vars for var in [x_var, y_var])\n",
    "#     is_avg = any(var in avg_vars for var in [x_var, y_var])\n",
    "    \n",
    "#     # Always include the timestamp column for time series plotting\n",
    "#     cols_to_select = ['timestamp_sentinel2', x_var]\n",
    "#     if y_var != 'None':\n",
    "#         cols_to_select.append(y_var)\n",
    "#     if is_remote_sensing or is_avg:\n",
    "#         if is_avg:\n",
    "#             cs_col = 'cs_AVG'\n",
    "#             cdf_col = 'cs_cdf_AVG'\n",
    "#         else:\n",
    "#             point_num = x_var.split('_')[0].replace('point', '')\n",
    "#             cs_col = f'point{point_num}_cs'\n",
    "#             cdf_col = f'point{point_num}_cs_cdf'\n",
    "        \n",
    "#         # Determine the appropriate column based on cloud_band selection\n",
    "#         if cloud_band == 'cs':\n",
    "#             filter_col = cs_col\n",
    "#         else:\n",
    "#             filter_col = cdf_col\n",
    "        \n",
    "#         cols_to_select.append(filter_col)\n",
    "        \n",
    "#         # Filter out rows with NaN values in the selected columns\n",
    "#         plot_data = data[cols_to_select].dropna()\n",
    "        \n",
    "#         # Apply cloud score filtering if enabled\n",
    "#         if filter_cloud:\n",
    "#             plot_data = plot_data[plot_data[filter_col] >= cloud_threshold]\n",
    "#     else:\n",
    "#         # Filter out rows with NaN values in the selected columns without cloud score filtering\n",
    "#         plot_data = data[cols_to_select].dropna()\n",
    "    \n",
    "#     # Drop zero-valued data points if enabled\n",
    "#     if drop_zero:\n",
    "#         plot_data = plot_data[plot_data[x_var] != 0]\n",
    "#         if y_var != 'None':\n",
    "#             plot_data = plot_data[plot_data[y_var] != 0]\n",
    "    \n",
    "#     # Add a small positive constant to avoid log(0) or negative values\n",
    "#     epsilon = 1e-10\n",
    "    \n",
    "#     # Take the logarithm of the values if enabled\n",
    "#     if log_x:\n",
    "#         plot_data[x_var] = np.log(plot_data[x_var] + epsilon)\n",
    "#     if y_var != 'None' and log_y:\n",
    "#         plot_data[y_var] = np.log(plot_data[y_var] + epsilon)\n",
    "    \n",
    "#     if plot_type == 'Scatter Plot':\n",
    "#         if y_var != 'None':\n",
    "#             plt.scatter(plot_data[x_var], plot_data[y_var], alpha=0.5)\n",
    "#             plt.xlabel(x_var)\n",
    "#             plt.ylabel(y_var)\n",
    "            \n",
    "#             # Calculate and display the correlation\n",
    "#             correlation = plot_data[[x_var, y_var]].corr().iloc[0, 1]\n",
    "#             plt.title(f'{plot_type} of {x_var} and {y_var}\\nCorrelation: {correlation:.2f}')\n",
    "#         else:\n",
    "#             plt.scatter(plot_data.index, plot_data[x_var], alpha=0.5)\n",
    "#             plt.xlabel('Index')\n",
    "#             plt.ylabel(x_var)\n",
    "#             plt.title(f'{plot_type} of {x_var}')\n",
    "        \n",
    "#     elif plot_type == 'Time Series Plot':\n",
    "#         if y_var != 'None':\n",
    "#             fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "#             color = 'tab:blue'\n",
    "#             ax1.set_xlabel('Time')\n",
    "#             ax1.set_ylabel(x_var, color=color)\n",
    "#             ax1.plot(plot_data['timestamp_sentinel2'], plot_data[x_var].rolling(window=window).mean(), color=color, label=f'{x_var} (Moving Average)')\n",
    "#             ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "#             ax2 = ax1.twinx()\n",
    "#             color = 'tab:red'\n",
    "#             ax2.set_ylabel(y_var, color=color)\n",
    "#             ax2.plot(plot_data['timestamp_sentinel2'], plot_data[y_var].rolling(window=window).mean(), color=color, label=f'{y_var} (Moving Average)')\n",
    "#             ax2.tick_params(axis='y', labelcolor=color)\n",
    "            \n",
    "#             fig.legend(loc='upper right')\n",
    "#             plt.title(f'{plot_type} of {x_var} and {y_var}')\n",
    "#         else:\n",
    "#             plt.figure(figsize=(15, 6))\n",
    "#             plt.plot(plot_data['timestamp_sentinel2'], plot_data[x_var].rolling(window=window).mean(), label=f'{x_var} (Moving Average)')\n",
    "#             plt.xlabel('Time')\n",
    "#             plt.ylabel(x_var)\n",
    "#             plt.legend()\n",
    "#             plt.title(f'{plot_type} of {x_var}')\n",
    "            \n",
    "#         # Adjust x-ticks to plot fewer of them, showing year and month only\n",
    "#         ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "#         ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#         plt.gcf().autofmt_xdate()\n",
    "            \n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# variables = data.columns.tolist()\n",
    "# if 'timestamp_sentinel2' in variables:\n",
    "#     variables.remove('timestamp_sentinel2')\n",
    "\n",
    "# interact(plot_data, \n",
    "#          plot_type=widgets.RadioButtons(options=['Scatter Plot', 'Time Series Plot'], description='Plot Type'),\n",
    "#          x_var=widgets.Dropdown(options=variables, description='X Variable'),\n",
    "#          y_var=widgets.Dropdown(options=['None'] + variables, description='Y Variable'),\n",
    "#          log_x=widgets.Checkbox(value=False, description='Log X Variable'),\n",
    "#          log_y=widgets.Checkbox(value=False, description='Log Y Variable'),\n",
    "#          window=widgets.IntSlider(value=5, min=1, max=50, step=1, description='Moving Avg Window'),\n",
    "#          filter_cloud=widgets.Checkbox(value=False, description='Filter by Cloud Score'),\n",
    "#          cloud_band=widgets.RadioButtons(options=['cs', 'cs_cdf'], description='Cloud Band'),\n",
    "#          cloud_threshold=widgets.FloatSlider(value=0.1, min=0.0, max=1.0, step=0.01, description='Cloud Threshold'),\n",
    "#          custom_var_expr=widgets.Text(value='', description='Custom Var Expr'),\n",
    "#          drop_zero=widgets.Checkbox(value=False, description='Drop Zero Values')\n",
    "# );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp_sentinel2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp_sentinel2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hzh166\\OneDrive - University of Canterbury\\DATA690_MSc_Thesis_Hao_37041529\\CodeWorks\\69660_New\\cleanup\\CODE_Plot.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMerged_Data_with_Discharge.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(file_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mtimestamp_sentinel2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data[\u001b[39m'\u001b[39;49m\u001b[39mtimestamp_sentinel2\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# List of remote sensing variables\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m remote_sensing_vars \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_B\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m col]\n",
      "File \u001b[1;32mc:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Program Files\\Anaconda3\\envs\\ee\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp_sentinel2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from ipywidgets import interact, widgets\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Merged_Data_with_Discharge.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data['timestamp_sentinel2'] = pd.to_datetime(data['timestamp_sentinel2'])\n",
    "\n",
    "# List of remote sensing variables\n",
    "remote_sensing_vars = [col for col in data.columns if '_B' in col]\n",
    "\n",
    "# List of average variables\n",
    "avg_vars = ['B2_AVG', 'B3_AVG', 'B4_AVG', 'B8_AVG', 'B8A_AVG', 'B11_AVG', 'B12_AVG']\n",
    "\n",
    "# Function to filter the data based on cloud score and other filters\n",
    "def filter_data(df, x_var, y_var, filter_cloud, cloud_band, cloud_threshold, drop_zero, log_x, log_y, log_threshold):\n",
    "    # Determine if the selected variable is a remote sensing variable or average variable\n",
    "    is_remote_sensing = any(var in remote_sensing_vars for var in [x_var, y_var])\n",
    "    is_avg = any(var in avg_vars for var in [x_var, y_var])\n",
    "    \n",
    "    # Always include the timestamp column for time series plotting\n",
    "    cols_to_select = ['timestamp_sentinel2', x_var]\n",
    "    if y_var != 'None':\n",
    "        cols_to_select.append(y_var)\n",
    "    if is_remote_sensing or is_avg:\n",
    "        if is_avg:\n",
    "            cs_col = 'cs_AVG'\n",
    "            cdf_col = 'cs_cdf_AVG'\n",
    "        else:\n",
    "            point_num = x_var.split('_')[0].replace('point', '')\n",
    "            cs_col = f'point{point_num}_cs'\n",
    "            cdf_col = f'point{point_num}_cs_cdf'\n",
    "        \n",
    "        # Determine the appropriate column based on cloud_band selection\n",
    "        filter_col = cs_col if cloud_band == 'cs' else cdf_col\n",
    "        cols_to_select.append(filter_col)\n",
    "        \n",
    "        # Filter out rows with NaN values in the selected columns\n",
    "        plot_data = df[cols_to_select].dropna()\n",
    "        \n",
    "        # Apply cloud score filtering if enabled\n",
    "        if filter_cloud:\n",
    "            plot_data = plot_data[plot_data[filter_col] >= cloud_threshold]\n",
    "    else:\n",
    "        # Filter out rows with NaN values in the selected columns without cloud score filtering\n",
    "        plot_data = df[cols_to_select].dropna()\n",
    "    \n",
    "    # Drop zero-valued data points if enabled\n",
    "    if drop_zero:\n",
    "        plot_data = plot_data[(plot_data[x_var] != 0)]\n",
    "        if y_var != 'None':\n",
    "            plot_data = plot_data[(plot_data[y_var] != 0)]\n",
    "    \n",
    "    # Add a small positive constant to avoid log(0) or negative values\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Take the logarithm of the values if enabled\n",
    "    if log_x:\n",
    "        plot_data[x_var] = np.log(plot_data[x_var] + epsilon)\n",
    "    if y_var != 'None' and log_y:\n",
    "        plot_data[y_var] = np.log(plot_data[y_var] + epsilon)\n",
    "    \n",
    "    # Filter out nearly zero values after log transformation interactively\n",
    "    plot_data = plot_data[plot_data[x_var] > log_threshold]\n",
    "    if y_var != 'None':\n",
    "        plot_data = plot_data[plot_data[y_var] > log_threshold]\n",
    "    \n",
    "    return plot_data\n",
    "\n",
    "# Function to plot data\n",
    "def plot_data(plot_type, x_var, y_var, log_x, log_y, window, filter_cloud, cloud_band, cloud_threshold, custom_var_expr, drop_zero, log_threshold, start_date, end_date):\n",
    "    plt.clf()  # Clear the current figure to prevent multiple subplots\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Apply custom variable expression if provided\n",
    "    if custom_var_expr:\n",
    "        try:\n",
    "            data['custom_var'] = eval(custom_var_expr, {\"data\": data, \"np\": np})\n",
    "            x_var = 'custom_var'\n",
    "        except Exception as e:\n",
    "            print(f\"Error in custom variable expression: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Filter data\n",
    "    plot_data = filter_data(data, x_var, y_var, filter_cloud, cloud_band, cloud_threshold, drop_zero, log_x, log_y, log_threshold)\n",
    "    \n",
    "    # Apply date range filter\n",
    "    if start_date and end_date:\n",
    "        plot_data = plot_data[(plot_data['timestamp_sentinel2'] >= start_date) & (plot_data['timestamp_sentinel2'] <= end_date)]\n",
    "    \n",
    "    if plot_type == 'Scatter Plot':\n",
    "        if y_var != 'None':\n",
    "            plt.scatter(plot_data[x_var], plot_data[y_var], alpha=0.5)\n",
    "            plt.xlabel(x_var)\n",
    "            plt.ylabel(y_var)\n",
    "            \n",
    "            # Calculate and display the correlation\n",
    "            correlation = plot_data[[x_var, y_var]].corr().iloc[0, 1]\n",
    "            plt.title(f'{plot_type} of {x_var} and {y_var}\\nCorrelation: {correlation:.2f}')\n",
    "        else:\n",
    "            plt.scatter(plot_data.index, plot_data[x_var], alpha=0.5)\n",
    "            plt.xlabel('Index')\n",
    "            plt.ylabel(x_var)\n",
    "            plt.title(f'{plot_type} of {x_var}')\n",
    "        \n",
    "    elif plot_type == 'Time Series Plot':\n",
    "        if y_var != 'None':\n",
    "            fig, ax1 = plt.subplots(figsize=(15, 6))\n",
    "            color = 'tab:blue'\n",
    "            ax1.set_xlabel('Time')\n",
    "            ax1.set_ylabel(x_var, color=color)\n",
    "            ax1.plot(plot_data['timestamp_sentinel2'], plot_data[x_var].rolling(window=window).mean(), color=color, label=f'{x_var} (Moving Average)')\n",
    "            ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "            ax2 = ax1.twinx()\n",
    "            color = 'tab:red'\n",
    "            ax2.set_ylabel(y_var, color=color)\n",
    "            ax2.plot(plot_data['timestamp_sentinel2'], plot_data[y_var].rolling(window=window).mean(), color=color, label=f'{y_var} (Moving Average)')\n",
    "            ax2.tick_params(axis='y', labelcolor=color)\n",
    "            \n",
    "            fig.legend(loc='upper right')\n",
    "            plt.title(f'{plot_type} of {x_var} and {y_var}')\n",
    "        else:\n",
    "            plt.figure(figsize=(15, 6))\n",
    "            plt.plot(plot_data['timestamp_sentinel2'], plot_data[x_var].rolling(window=window).mean(), label=f'{x_var} (Moving Average)')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel(x_var)\n",
    "            plt.legend()\n",
    "            plt.title(f'{plot_type} of {x_var}')\n",
    "            \n",
    "        # Adjust x-ticks to plot fewer of them, showing year and month only\n",
    "        ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        plt.gcf().autofmt_xdate()\n",
    "            \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "variables = data.columns.tolist()\n",
    "if 'timestamp_sentinel2' in variables:\n",
    "    variables.remove('timestamp_sentinel2')\n",
    "\n",
    "# Interactive plot function\n",
    "def interactive_plot(plot_type, x_var, y_var, log_x, log_y, window, filter_cloud, cloud_band, cloud_threshold, custom_var_expr, drop_zero, log_threshold, date_range):\n",
    "    start_date, end_date = convert_date_range_to_datetime(date_range)\n",
    "    plot_data(plot_type, x_var, y_var, log_x, log_y, window, filter_cloud, cloud_band, cloud_threshold, custom_var_expr, drop_zero, log_threshold, start_date, end_date)\n",
    "\n",
    "# Define the date range slider\n",
    "date_range_slider = widgets.SelectionRangeSlider(\n",
    "    options=[(date.strftime('%Y-%m'), date) for date in pd.date_range(data['timestamp_sentinel2'].min(), data['timestamp_sentinel2'].max(), freq='MS')],\n",
    "    index=(0, len(pd.date_range(data['timestamp_sentinel2'].min(), data['timestamp_sentinel2'].max(), freq='MS')) - 1),\n",
    "    description='Date Range',\n",
    "    orientation='horizontal',\n",
    "    layout={'width': '800px'}\n",
    ")\n",
    "\n",
    "# Convert the date range slider values to datetime\n",
    "def convert_date_range_to_datetime(date_range):\n",
    "    return (pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1]))\n",
    "\n",
    "interact(interactive_plot, \n",
    "         plot_type=widgets.RadioButtons(options=['Scatter Plot', 'Time Series Plot'], description='Plot Type'),\n",
    "         x_var=widgets.Dropdown(options=variables, description='X Variable'),\n",
    "         y_var=widgets.Dropdown(options=['None'] + variables, description='Y Variable'),\n",
    "         log_x=widgets.Checkbox(value=False, description='Log X Variable'),\n",
    "         log_y=widgets.Checkbox(value=False, description='Log Y Variable'),\n",
    "         window=widgets.IntSlider(value=5, min=1, max=50, step=1, description='Moving Avg Window'),\n",
    "         filter_cloud=widgets.Checkbox(value=False, description='Filter by Cloud Score'),\n",
    "         cloud_band=widgets.RadioButtons(options=['cs', 'cs_cdf'], description='Cloud Band'),\n",
    "         cloud_threshold=widgets.FloatSlider(value=0.1, min=0.0, max=1.0, step=0.01, description='Cloud Threshold'),\n",
    "         custom_var_expr=widgets.Text(value='', description='Custom Var Expr'),\n",
    "         drop_zero=widgets.Checkbox(value=False, description='Drop Zero Values'),\n",
    "         log_threshold=widgets.FloatSlider(value=np.log(1 + 1e-10), min=-10.0, max=1.0, step=0.01, description='Log Threshold'),\n",
    "         date_range=date_range_slider\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column 'timestamp_sentinel2' not found in the dataset.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hzh166\\OneDrive - University of Canterbury\\DATA690_MSc_Thesis_Hao_37041529\\CodeWorks\\69660_New\\cleanup\\CODE_Plot.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mtimestamp_sentinel2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(data[\u001b[39m'\u001b[39m\u001b[39mtimestamp_sentinel2\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimestamp_sentinel2\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not found in the dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Define filter parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hzh166/OneDrive%20-%20University%20of%20Canterbury/DATA690_MSc_Thesis_Hao_37041529/CodeWorks/69660_New/cleanup/CODE_Plot.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cloud_threshold \u001b[39m=\u001b[39m \u001b[39m0.10\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column 'timestamp_sentinel2' not found in the dataset.\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "file_path = 'Merged_Data_with_Discharge.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check if the timestamp_sentinel2 column exists\n",
    "if 'timestamp_sentinel2' in data.columns:\n",
    "    data['timestamp_sentinel2'] = pd.to_datetime(data['timestamp_sentinel2'])\n",
    "else:\n",
    "    raise KeyError(\"Column 'timestamp_sentinel2' not found in the dataset.\")\n",
    "\n",
    "# Define filter parameters\n",
    "cloud_threshold = 0.10\n",
    "moving_avg_window = 5\n",
    "cloud_score_column = 'cs'\n",
    "\n",
    "\n",
    "\n",
    "# Filter data based on cloud score threshold\n",
    "filtered_data = data[data[cloud_score_column] <= cloud_threshold]\n",
    "\n",
    "# Drop rows with zero values in 'point1_B2' if required\n",
    "filtered_data = filtered_data[filtered_data['point1_B2'] != 0]\n",
    "\n",
    "# Apply moving average to 'point1_B2'\n",
    "filtered_data['point1_B2_MA'] = filtered_data['point1_B2'].rolling(window=moving_avg_window).mean()\n",
    "\n",
    "# Plot scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtered_data['timestamp_sentinel2'], filtered_data['point1_B2_MA'], alpha=0.5, label='Point1 B2 Moving Avg')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Point1 B2 Moving Avg')\n",
    "plt.title('Scatter Plot of Point1 B2 with Moving Average')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
